{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "795f93dc-7834-4525-bb79-57a3888baeab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import os  \n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3215e-be5d-4c0f-8658-ee06b64ed2ff",
   "metadata": {},
   "source": [
    "# DATA PRE-PROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c8ea88-4b1b-4952-9442-06737368ba12",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = '../data/raw/bot_detection_data.csv'\n",
    "data = pd.read_csv(raw_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b49a686-1718-4edd-99b0-676273364889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Retweet Count</th>\n",
       "      <th>Mention Count</th>\n",
       "      <th>Follower Count</th>\n",
       "      <th>Verified</th>\n",
       "      <th>Bot Label</th>\n",
       "      <th>Location</th>\n",
       "      <th>Created At</th>\n",
       "      <th>Hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>132131</td>\n",
       "      <td>flong</td>\n",
       "      <td>Station activity person against natural majori...</td>\n",
       "      <td>85</td>\n",
       "      <td>1</td>\n",
       "      <td>2353</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Adkinston</td>\n",
       "      <td>2020-05-11 15:29:50</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>289683</td>\n",
       "      <td>hinesstephanie</td>\n",
       "      <td>Authority research natural life material staff...</td>\n",
       "      <td>55</td>\n",
       "      <td>5</td>\n",
       "      <td>9617</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Sanderston</td>\n",
       "      <td>2022-11-26 05:18:10</td>\n",
       "      <td>both live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>779715</td>\n",
       "      <td>roberttran</td>\n",
       "      <td>Manage whose quickly especially foot none to g...</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>4363</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>Harrisonfurt</td>\n",
       "      <td>2022-08-08 03:16:54</td>\n",
       "      <td>phone ahead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>696168</td>\n",
       "      <td>pmason</td>\n",
       "      <td>Just cover eight opportunity strong policy which.</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>2242</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Martinezberg</td>\n",
       "      <td>2021-08-14 22:27:05</td>\n",
       "      <td>ever quickly new I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704441</td>\n",
       "      <td>noah87</td>\n",
       "      <td>Animal sign six data good or.</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>8438</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Camachoville</td>\n",
       "      <td>2020-04-13 21:24:21</td>\n",
       "      <td>foreign mention</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>491196</td>\n",
       "      <td>uberg</td>\n",
       "      <td>Want but put card direction know miss former h...</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>9911</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Lake Kimberlyburgh</td>\n",
       "      <td>2023-04-20 11:06:26</td>\n",
       "      <td>teach quality ten education any</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>739297</td>\n",
       "      <td>jessicamunoz</td>\n",
       "      <td>Provide whole maybe agree church respond most ...</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>9900</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>Greenbury</td>\n",
       "      <td>2022-10-18 03:57:35</td>\n",
       "      <td>add walk among believe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>674475</td>\n",
       "      <td>lynncunningham</td>\n",
       "      <td>Bring different everyone international capital...</td>\n",
       "      <td>43</td>\n",
       "      <td>3</td>\n",
       "      <td>6313</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>Deborahfort</td>\n",
       "      <td>2020-07-08 03:54:08</td>\n",
       "      <td>onto admit artist first</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>167081</td>\n",
       "      <td>richardthompson</td>\n",
       "      <td>Than about single generation itself seek sell ...</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>6343</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Stephenside</td>\n",
       "      <td>2022-03-22 12:13:44</td>\n",
       "      <td>star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>311204</td>\n",
       "      <td>daniel29</td>\n",
       "      <td>Here morning class various room human true bec...</td>\n",
       "      <td>91</td>\n",
       "      <td>4</td>\n",
       "      <td>4006</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>Novakberg</td>\n",
       "      <td>2022-12-03 06:11:07</td>\n",
       "      <td>home</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       User ID         Username  \\\n",
       "0       132131            flong   \n",
       "1       289683   hinesstephanie   \n",
       "2       779715       roberttran   \n",
       "3       696168           pmason   \n",
       "4       704441           noah87   \n",
       "...        ...              ...   \n",
       "49995   491196            uberg   \n",
       "49996   739297     jessicamunoz   \n",
       "49997   674475   lynncunningham   \n",
       "49998   167081  richardthompson   \n",
       "49999   311204         daniel29   \n",
       "\n",
       "                                                   Tweet  Retweet Count  \\\n",
       "0      Station activity person against natural majori...             85   \n",
       "1      Authority research natural life material staff...             55   \n",
       "2      Manage whose quickly especially foot none to g...              6   \n",
       "3      Just cover eight opportunity strong policy which.             54   \n",
       "4                          Animal sign six data good or.             26   \n",
       "...                                                  ...            ...   \n",
       "49995  Want but put card direction know miss former h...             64   \n",
       "49996  Provide whole maybe agree church respond most ...             18   \n",
       "49997  Bring different everyone international capital...             43   \n",
       "49998  Than about single generation itself seek sell ...             45   \n",
       "49999  Here morning class various room human true bec...             91   \n",
       "\n",
       "       Mention Count  Follower Count  Verified  Bot Label            Location  \\\n",
       "0                  1            2353     False          1           Adkinston   \n",
       "1                  5            9617      True          0          Sanderston   \n",
       "2                  2            4363      True          0        Harrisonfurt   \n",
       "3                  5            2242      True          1        Martinezberg   \n",
       "4                  3            8438     False          1        Camachoville   \n",
       "...              ...             ...       ...        ...                 ...   \n",
       "49995              0            9911      True          1  Lake Kimberlyburgh   \n",
       "49996              5            9900     False          1           Greenbury   \n",
       "49997              3            6313      True          1         Deborahfort   \n",
       "49998              1            6343     False          0         Stephenside   \n",
       "49999              4            4006     False          0           Novakberg   \n",
       "\n",
       "                Created At                         Hashtags  \n",
       "0      2020-05-11 15:29:50                              NaN  \n",
       "1      2022-11-26 05:18:10                        both live  \n",
       "2      2022-08-08 03:16:54                      phone ahead  \n",
       "3      2021-08-14 22:27:05               ever quickly new I  \n",
       "4      2020-04-13 21:24:21                  foreign mention  \n",
       "...                    ...                              ...  \n",
       "49995  2023-04-20 11:06:26  teach quality ten education any  \n",
       "49996  2022-10-18 03:57:35           add walk among believe  \n",
       "49997  2020-07-08 03:54:08          onto admit artist first  \n",
       "49998  2022-03-22 12:13:44                             star  \n",
       "49999  2022-12-03 06:11:07                             home  \n",
       "\n",
       "[50000 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d23156b-be01-4f2e-9b68-3383a1876496",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"Created At\"] = pd.to_datetime(data[\"Created At\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "db52a417-8b94-4295-b3c8-559906f697e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 14 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   User ID           50000 non-null  int64         \n",
      " 1   Username          50000 non-null  object        \n",
      " 2   Tweet             50000 non-null  object        \n",
      " 3   Retweet Count     50000 non-null  int64         \n",
      " 4   Mention Count     50000 non-null  int64         \n",
      " 5   Follower Count    50000 non-null  int64         \n",
      " 6   Verified          50000 non-null  bool          \n",
      " 7   Bot Label         50000 non-null  int64         \n",
      " 8   Location          50000 non-null  object        \n",
      " 9   Created At        50000 non-null  datetime64[ns]\n",
      " 10  Hashtags          50000 non-null  object        \n",
      " 11  Tokenized Tweet   50000 non-null  object        \n",
      " 12  Stemmed Tweet     50000 non-null  object        \n",
      " 13  Lemmatized Tweet  50000 non-null  object        \n",
      "dtypes: bool(1), datetime64[ns](1), int64(5), object(7)\n",
      "memory usage: 5.0+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c002237-f3a0-42e0-bc8a-997ded1f85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Hashtags'] = data['Hashtags'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80ea3fe0-a1b8-4e05-b7a9-996f3ebe29a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Username'] = data['Username'].str.lower()\n",
    "data['Tweet'] = data['Tweet'].str.lower() \n",
    "data['Hashtags'] = data['Hashtags'].str.lower()\n",
    "data['Location'] = data['Location'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ccfc27-f9b7-488e-adfd-281377314aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "150eb02c-ab1b-48f7-8611-9466aefe4330",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "data['Hashtags'] = data['Hashtags'].str.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22e3022f-fbb7-4721-907c-dd1b71a97c07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/sush/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "data['Tokenized Tweet'] = data['Tweet'].apply(nltk.word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c23b3882-39f1-4050-8566-48689078ee86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/sush/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['Tokenized Tweet'] = data['Tokenized Tweet'].apply(lambda x: [word for word in x if word not in stop_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "be8e828f-382a-4969-98f9-b7374bcdaf43",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "data['Stemmed Tweet'] = data['Tokenized Tweet'].apply(lambda x: [stemmer.stem(word) for word in x]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a533b897-64ef-48b6-944c-1ffd4115a2ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/sush/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['Lemmatized Tweet'] = data['Tokenized Tweet'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b152378a-9ce2-43fd-8572-27dae84f58f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Stemmed Tweet'] = data['Stemmed Tweet'].apply(lambda x: ' '.join(x))\n",
    "data['Lemmatized Tweet'] = data['Lemmatized Tweet'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b726486-3bd3-49cb-b9a0-4ad26cfe72df",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = vectorizer.fit_transform(data['Lemmatized Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "94469d03-7b2c-4c22-833b-64d0f28caed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['Bot Label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f530faa-d511-4d87-b47d-a4bb374f28ca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# MODEL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b96c4f26-6165-4ee6-a788-af26adaa20cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "974950a1-41f1-4348-bcf3-6e3168312d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a888f17-73e9-4ee6-b6cd-aa9a6ff443f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5039\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.50      4968\n",
      "           1       0.51      0.50      0.50      5032\n",
      "\n",
      "    accuracy                           0.50     10000\n",
      "   macro avg       0.50      0.50      0.50     10000\n",
      "weighted avg       0.50      0.50      0.50     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e348213-fa59-4bcd-b5ac-053b9b098fbc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_lab1_env",
   "language": "python",
   "name": "mlflow_lab1_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
