import pandas as pd 
import numpy as np 
import seaborn as sns
import matplotlib.pyplot as plt
import os  
import string
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.stem import WordNetLemmatizer
from collections import Counter





raw_path = '../data/raw/bot_detection_data.csv'


data = pd.read_csv(raw_path)


data.head()


data.info()


data.shape


data.describe()


data.isna().sum()


data["Bot Label"].value_counts()


data["Username"].nunique()


data["User ID"].nunique() 


data["Verified"].value_counts()


data["Location"].nunique()


data["Created At"] = pd.to_datetime(data["Created At"])


data.info()


data['Created At'].plot(figsize=(10, 6), kind='line')
plt.title('Frequency of Tweets on Each day')
plt.xlabel('Date')
plt.ylabel('Frequency')
plt.show()


plt.figure(figsize=(10,6))
sns.countplot(x='Verified', hue = 'Bot Label', data = data)
plt.title("Number of Verfied and Unverfied tweets of BOT and NOT")
plt.xlabel("Verified label")
plt.ylabel("Number of tweets")
plt.show()


plt.figure(figsize=(8, 6))
sns.countplot(x='Verified', hue='Bot Label', data=data)
plt.title('Verified Status by Bot Label')
plt.show()


sns.countplot(x='Retweet Count', data=data[data['Bot Label']==0], order=sorted(data['Retweet Count'].unique()))
plt.title('Frequency of Tweets on Each day')
plt.xlabel('Date')
plt.ylabel('Frequency')
plt.show()


plt.figure(figsize=(10, 6))
sns.histplot(data['Follower Count'], kde=True, bins=30)
plt.title('Distribution of Follower Count')
plt.xlabel('Follower Count')
plt.ylabel('Frequency')
plt.show()



plt.figure(figsize=(10, 6))
sns.histplot(data['Retweet Count'], kde=True, bins=30)
plt.title('Distribution of Retweet Count')
plt.xlabel('Retweet Count')
plt.ylabel('Frequency')
plt.show()



plt.figure(figsize=(10, 6))
sns.boxplot(x='Bot Label', y='Follower Count', data=data)
plt.title('Follower Count by Bot Label')
plt.show()



plt.figure(figsize=(10, 6))
data['Created At'].groupby(data['Created At'].dt.date).count().plot(kind='line')
plt.title('Number of Tweets Over Time')
plt.xlabel('Date')
plt.ylabel('Number of Tweets')
plt.show()



plt.figure(figsize=(10, 6))
data[data['Bot Label'] == 1]['Created At'].groupby(data['Created At'].dt.date).count().plot(kind='line', label='Bot')
data[data['Bot Label'] == 0]['Created At'].groupby(data['Created At'].dt.date).count().plot(kind='line', label='Not Bot')
plt.title('Number of Tweets Over Time by Bot Label')
plt.xlabel('Date')
plt.ylabel('Number of Tweets')
plt.legend()
plt.show()






data['Hashtags'] = data['Hashtags'].fillna('')


hashtags = data['Hashtags'].str.split(expand=True).stack().value_counts()

# Plot the top 10 most common hashtags
plt.figure(figsize=(10, 6))
sns.barplot(x=hashtags.head(10).values, y=hashtags.head(10).index, orient='h')
plt.title('Top 10 Most Common Hashtags')
plt.xlabel('Count')
plt.show()


plt.figure(figsize=(10, 8))
sns.heatmap(data.corr(), annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix')
plt.show()








data.head()


data.info()


data.isna().sum()





data_2 = data
data_2['Username'] = data_2['Username'].str.lower()
data_2['Tweet'] = data_2['Tweet'].str.lower() 
data_2['Hashtags'] = data_2['Hashtags'].str.lower()
data_2['Location'] = data_2['Location'].str.lower()


data_2['Tweet'] = data_2['Tweet'].str.translate(str.maketrans('', '', string.punctuation))
data_2['Hashtags'] = data_2['Hashtags'].str.translate(str.maketrans('', '', string.punctuation))


nltk.download('punkt')


data_2['Tokenized Tweet'] = data_2['Tweet'].apply(nltk.word_tokenize)


nltk.download('stopwords')


stop_words = set(stopwords.words('english'))


data_2['Tokenized Tweet'] = data_2['Tokenized Tweet'].apply(lambda x: [word for word in x if word not in stop_words])


stemmer = PorterStemmer()
data_2['Stemmed Tweet'] = data_2['Tokenized Tweet'].apply(lambda x: [stemmer.stem(word) for word in x]) 


nltk.download('wordnet')
lemmatizer = WordNetLemmatizer()


data_2['Lemmatized Tweet'] = data_2['Tokenized Tweet'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])


data_2.head()





all_words = [word for tokens in data_2['Lemmatized Tweet'] for word in tokens]
word_freq = Counter(all_words)
common_words = word_freq.most_common(20)

common_words_df = pd.DataFrame(common_words, columns=['Word', 'Count'])

plt.figure(figsize=(10, 6))
sns.barplot(x='Count', y='Word', data=common_words_df)
plt.title('Top 20 Most Common Words')
plt.show()


data_2['Hashtags'] = data_2['Hashtags'].str.split()
all_hashtags = [hashtag for sublist in data_2['Hashtags'].dropna() for hashtag in sublist]
hashtag_freq = Counter(all_hashtags)
common_hashtags = hashtag_freq.most_common(20)

common_hashtags_df = pd.DataFrame(common_hashtags, columns=['Hashtag', 'Count'])
plt.figure(figsize=(10, 6))
sns.barplot(x='Count', y='Hashtag', data=common_hashtags_df)
plt.title('Top 20 Most Common Hashtags')
plt.show()





from wordcloud import WordCloud
tweet_words = ' '.join([text for text in data_2['Tweet']])
wordcloud = WordCloud(width=800, height=400, max_font_size=100, max_words=100, background_color='white').generate(tweet_words)

plt.figure(figsize=(10, 6))
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis('off')
plt.title('Word Cloud for Tweets')
plt.show()



bot_tweets = data_2[data_2['Bot Label'] == 1]['Lemmatized Tweet']
non_bot_tweets = data_2[data_2['Bot Label'] == 0]['Lemmatized Tweet']

bot_words = [word for tokens in bot_tweets for word in tokens]
non_bot_words = [word for tokens in non_bot_tweets for word in tokens]

bot_word_freq = Counter(bot_words)
non_bot_word_freq = Counter(non_bot_words)

bot_common_words_df = pd.DataFrame(bot_word_freq.most_common(20), columns=['Word', 'Count'])
non_bot_common_words_df = pd.DataFrame(non_bot_word_freq.most_common(20), columns=['Word', 'Count'])

plt.figure(figsize=(14, 6))

plt.subplot(1, 2, 1)
sns.barplot(x='Count', y='Word', data=bot_common_words_df, color='red')
plt.title('Top 20 Words Used by Bots')

plt.subplot(1, 2, 2)
sns.barplot(x='Count', y='Word', data=non_bot_common_words_df, color='blue')
plt.title('Top 20 Words Used by Non-Bots')

plt.tight_layout()
plt.show()


bot_word_freq



